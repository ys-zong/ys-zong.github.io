---
---

@article{zong2024safety,
  title={Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models},
  author={Zong, Yongshuo and Bohdal, Ondrej and Yu, Tingyang and Yang, Yongxin and Hospedales, Timothy},
  journal={ICML},
  year={2024}
}

@article{zong2024fool,
  title={Fool your (vision and) language model with embarrassingly simple permutations},
  author={Zong, Yongshuo and Yu, Tingyang and Zhao, Bingchen and Chavhan, Ruchika and Hospedales, Timothy},
  journal={ICML},
  year={2024}
}

@inproceedings{zhang2024if,
  title={What if the tv was off? examining counterfactual reasoning abilities of multi-modal language models},
  author={Zhang, Letian and Zhai, Xiaotong and Zhao, Zhongkai and Zong, Yongshuo and Wen, Xin and Zhao, Bingchen},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{bohdal2023meta,
  title={Meta omnium: A benchmark for general-purpose learning-to-learn},
  author={Bohdal, Ondrej and Tian, Yinbing and Zong, Yongshuo and Chavhan, Ruchika and Li, Da and Gouk, Henry and Guo, Li and Hospedales, Timothy},
  booktitle={CVPR},
  year={2023}
}

@article{zong2023medfair,
  title={MEDFAIR: benchmarking fairness for medical imaging},
  author={Zong, Yongshuo and Yang, Yongxin and Hospedales, Timothy},
  journal={ICLR},
  year={2023}
}
